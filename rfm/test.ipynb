{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 13:45:43,817 - Training LaplaceRFM\n",
      "2025-03-24 13:45:43,817 - Training LaplaceRFM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders provided\n",
      "Round 0, Train Acc: 100.00%, Test Acc: 91.83%\n",
      "Round 0, Test MSE: 0.0616\n",
      "Sampling AGOP on maximum of 10016 total points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 44/625 [00:22<05:02,  1.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Huấn luyện từng mô hình và ghi log, truyền thêm M_batch_size và p_batch_size để tránh lỗi\u001b[39;00m\n\u001b[0;32m     69\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining LaplaceRFM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m \u001b[43mlaplace_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43miters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use the proper parameter name (classification instead of classif)\u001b[39;49;00m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_points_to_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mM_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_p_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \n\u001b[0;32m     80\u001b[0m \u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\UIT\\New AGOP\\recursive_feature_machines\\rfm\\recursive_feature_machine.py:262\u001b[0m, in \u001b[0;36mRecursiveFeatureMachine.fit\u001b[1;34m(self, train_data, test_data, iters, method, classification, verbose, M_batch_size, return_best_params, bs, return_Ms, lr_scale, total_points_to_sample, solver, fit_last_M, prefit_eigenpro, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_best_params:\n\u001b[0;32m    257\u001b[0m     best_metric, best_alphas, best_M, best_sqrtM, best_iter, best_bandwidth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_best_params(best_metric, best_alphas, \n\u001b[0;32m    258\u001b[0m                                                                                                     best_M, best_sqrtM, \n\u001b[0;32m    259\u001b[0m                                                                                                     best_iter, best_bandwidth, \n\u001b[0;32m    260\u001b[0m                                                                                                     test_acc \u001b[38;5;28;01mif\u001b[39;00m classification \u001b[38;5;28;01melse\u001b[39;00m test_mse, i)\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_M\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mM_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m           \u001b[49m\u001b[43muse_sqrtM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_sqrtM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_points_to_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_points_to_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_Ms:\n\u001b[0;32m    267\u001b[0m     Ms\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor_copy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM))\n",
      "File \u001b[1;32md:\\UIT\\New AGOP\\recursive_feature_machines\\rfm\\recursive_feature_machine.py:349\u001b[0m, in \u001b[0;36mRecursiveFeatureMachine.fit_M\u001b[1;34m(self, samples, labels, p_batch_size, M_batch_size, verbose, total_points_to_sample, use_sqrtM, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, bids \u001b[38;5;129;01min\u001b[39;00m tenumerate(batches):\n\u001b[0;32m    348\u001b[0m         torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m--> 349\u001b[0m         M\u001b[38;5;241m.\u001b[39madd_(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_M\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbids\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_batch_size\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m bids \u001b[38;5;129;01min\u001b[39;00m batches:\n",
      "File \u001b[1;32md:\\UIT\\New AGOP\\recursive_feature_machines\\rfm\\recursive_feature_machine.py:473\u001b[0m, in \u001b[0;36mLaplaceRFM.update_M\u001b[1;34m(self, samples, p_batch_size)\u001b[0m\n\u001b[0;32m    470\u001b[0m temp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p_batch \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39marange(p)\u001b[38;5;241m.\u001b[39msplit(p_batch_size):\n\u001b[0;32m    472\u001b[0m     temp \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m K[:, p_batch] \u001b[38;5;241m@\u001b[39m ( \u001b[38;5;66;03m# (n, len(p_batch))\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[p_batch,:]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mlen\u001b[39m(p_batch), c, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenters[p_batch,:] \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp_batch\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m1\u001b[39m, d)\n\u001b[0;32m    474\u001b[0m     )\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m    475\u001b[0m         \u001b[38;5;28mlen\u001b[39m(p_batch), c \u001b[38;5;241m*\u001b[39m d\n\u001b[0;32m    476\u001b[0m     )  \u001b[38;5;66;03m# (len(p_batch), cd)\u001b[39;00m\n\u001b[0;32m    478\u001b[0m centers_term \u001b[38;5;241m=\u001b[39m temp\u001b[38;5;241m.\u001b[39mview(n, c, d)\n\u001b[0;32m    480\u001b[0m samples_term \u001b[38;5;241m=\u001b[39m samples_term \u001b[38;5;241m*\u001b[39m (samples \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM)\u001b[38;5;241m.\u001b[39mreshape(n, \u001b[38;5;241m1\u001b[39m, d)\n",
      "File \u001b[1;32mc:\\Users\\hoang\\anaconda3\\envs\\clean_env\\Lib\\site-packages\\torch\\_tensor.py:1083\u001b[0m, in \u001b[0;36mTensor.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;21m__neg__\u001b[39m \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mTensorBase\u001b[38;5;241m.\u001b[39mneg\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;21m__abs__\u001b[39m \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mTensorBase\u001b[38;5;241m.\u001b[39mabs\n\u001b[1;32m-> 1083\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1085\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from rfm import LaplaceRFM, GeneralizedLaplaceRFM, GaussRFM, NTKModel\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "\n",
    "# Cấu hình logging: ghi log vào file và in ra console\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "\n",
    "# File handler: ghi log vào output.txt\n",
    "file_handler = logging.FileHandler(\"output.txt\")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Console handler: in log ra console\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setFormatter(formatter)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# Hàm chuyển đổi batch: chuyển đổi nhãn thành one-hot encoding với 10 lớp\n",
    "def one_hot_collate(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    images = torch.stack(images, 0)\n",
    "    labels = torch.tensor(labels)\n",
    "    # Chuyển đổi nhãn sang one-hot (float)\n",
    "    labels = F.one_hot(labels, num_classes=10).float()\n",
    "    return images, labels\n",
    "\n",
    "# Thiết lập thiết bị và bộ nhớ GPU (nếu có)\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    DEV_MEM_GB = torch.cuda.get_device_properties(DEVICE).total_memory // 1024**3 - 1 \n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    DEV_MEM_GB = 8\n",
    "\n",
    "# Định nghĩa transform: chuyển đổi ảnh MNIST thành tensor và làm phẳng thành vector 784 chiều\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))\n",
    "])\n",
    "\n",
    "# Tải dataset MNIST cho training và testing\n",
    "full_train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Chia tập train ra thành một phần nhỏ để tránh làm đầy bộ nhớ\n",
    "subset_size = 10000  # Có thể điều chỉnh theo khả năng của máy\n",
    "train_subset, _ = random_split(full_train_dataset, [subset_size, len(full_train_dataset) - subset_size])\n",
    "\n",
    "# Tạo DataLoader cho tập train và test, sử dụng collate_fn để chuyển đổi nhãn\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, collate_fn=one_hot_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=one_hot_collate)\n",
    "\n",
    "# Set a default p_batch_size value that will be used when None is passed\n",
    "default_p_batch_size = 8\n",
    "\n",
    "# Khởi tạo các mô hình với cùng tham số cơ bản\n",
    "laplace_model = LaplaceRFM(bandwidth=1., device=DEVICE, mem_gb=DEV_MEM_GB, diag=False, p_batch_size=default_p_batch_size)\n",
    "generalized_model = GeneralizedLaplaceRFM(bandwidth=1., device=DEVICE, mem_gb=DEV_MEM_GB, diag=False, p_batch_size=default_p_batch_size)\n",
    "gauss_model = GaussRFM(bandwidth=1., device=DEVICE, mem_gb=DEV_MEM_GB, diag=False, p_batch_size=default_p_batch_size)\n",
    "ntk_model = NTKModel(device=DEVICE, mem_gb=DEV_MEM_GB, diag=False, p_batch_size=default_p_batch_size)\n",
    "\n",
    "# Huấn luyện từng mô hình và ghi log, truyền thêm M_batch_size và p_batch_size để tránh lỗi\n",
    "logger.info(\"Training LaplaceRFM\")\n",
    "laplace_model.fit(\n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    loader=True, \n",
    "    iters=3,\n",
    "    classification=True,  # Use the proper parameter name (classification instead of classif)\n",
    "    total_points_to_sample=subset_size,\n",
    "    M_batch_size=batch_size,\n",
    "    p_batch_size=default_p_batch_size,\n",
    "\n",
    " )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
