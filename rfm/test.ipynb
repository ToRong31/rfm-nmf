{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\hoang\\_netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtorong31\u001b[0m (\u001b[33mtorong31-uit\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to prefit Eigenpro with 70000 points: 0.37864041328430176 seconds\n",
      "NMF with init='nndsvd' completed.\n",
      "Final reconstruction error (Frobenius norm): 31.5235\n",
      "Using NMF-based projection with rank=2, eta=0.0010, bs=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0 epochs, 0.1s)\ttrain mse: 0.0000 \tval mse: 0.6130\ttrain acc: 0.5990 \tval acc: 0.3390\n",
      "New best multiclass-acc: 0.3390\n",
      "Round 0, Test Acc: 33.90%\n",
      "Round 0, Test MSE: 0.6130\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "You must call wandb.init() before wandb.log()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m y_test \u001b[38;5;241m=\u001b[39m fstar(X_test)\n\u001b[0;32m     27\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlogin(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf3dc9c85e2330a83d886a54b44d32768b2d7b60\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43miters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meigenpro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     36\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\UIT\\New AGOP\\rfm\\rfm\\recursive_feature_machine.py:266\u001b[0m, in \u001b[0;36mRecursiveFeatureMachine.fit\u001b[1;34m(self, train_data, test_data, iters, method, classification, verbose, M_batch_size, return_best_params, bs, return_Ms, lr_scale, total_points_to_sample, solver, fit_last_M, prefit_eigenpro, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m    264\u001b[0m log_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch_time_sec\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m elapsed_time\n\u001b[1;32m--> 266\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# if classification and accuracy higher, or if regression and mse lower\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_best_params:\n",
      "File \u001b[1;32mc:\\Users\\hoang\\anaconda3\\envs\\clean_env\\Lib\\site-packages\\wandb\\sdk\\lib\\preinit.py:36\u001b[0m, in \u001b[0;36mPreInitCallable.<locals>.preinit_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreinit_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must call wandb.init() before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from rfm import LaplaceRFM\n",
    "import wandb\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    # find GPU memory in GB, keeping aside 1GB for safety\n",
    "    DEV_MEM_GB = torch.cuda.get_device_properties(DEVICE).total_memory//1024**3 - 1 \n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    DEV_MEM_GB = 8\n",
    "\n",
    "def fstar(X):\n",
    "    return torch.cat([(X[:,0]>0)[:,None], \n",
    "\t(X[:,1]<0.5)[:,None]], axis=1).float()\n",
    "\n",
    "model = LaplaceRFM(bandwidth=1., device=DEVICE, mem_gb=DEV_MEM_GB, diag=False)\n",
    "\n",
    "n = 1000 # samples\n",
    "d = 100  # dimension\n",
    "c = 2    # classes\n",
    "\n",
    "X_train = torch.randn(n, d, device=DEVICE)\n",
    "X_test = torch.randn(n, d, device=DEVICE)\n",
    "y_train = fstar(X_train)\n",
    "y_test = fstar(X_test)\n",
    "\n",
    "wandb.login(key='cf3dc9c85e2330a83d886a54b44d32768b2d7b60')\n",
    "wandb.init(project=\"rfm-nmf\", name=\"Try1\")\n",
    "\n",
    "model.fit(\n",
    "    (X_train, y_train), \n",
    "    (X_test, y_test), \n",
    "    iters=5,\n",
    "    classification=True,\n",
    "    epochs=5,\n",
    "    method='eigenpro'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
