{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hoang\\anaconda3\\envs\\clean_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KernelModel with Laplace kernel...\n",
      "Training KernelModel with Laplace kernel...\n",
      "Using NMF-based projection with rank=3, eta=0.0031, bs=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NMF projection\n",
      "grad shape: torch.Size([33, 3]), kmat shape: torch.Size([33, 500])\n",
      "W_nmf shape: torch.Size([3, 3]), H_nmf shape: torch.Size([3, 500]), S_nmf shape: torch.Size([3, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x500 and 33x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Huấn luyện mô hình\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining KernelModel with Laplace kernel...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mkernel_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Số lượng epochs\u001b[39;49;00m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmem_gb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Giới hạn bộ nhớ GPU\u001b[39;49;00m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_subsamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Số lượng mẫu con để tính toán\u001b[39;49;00m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Batch size\u001b[39;49;00m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Learning rate\u001b[39;49;00m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     49\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Dự đoán trên tập validation\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicting on validation data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\UIT\\nsNMF\\rfm-nmf\\rfm\\rfm\\nmfhtr.py:241\u001b[0m, in \u001b[0;36mKernelModel.fit\u001b[1;34m(self, X_train, y_train, X_val, y_val, epochs, mem_gb, n_subsamples, bs, eta, n_eval, run_epoch_eval, lr_scale, verbose, seed, classification, threshold, early_stopping_window_size, eval_interval)\u001b[0m\n\u001b[0;32m    238\u001b[0m     x_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor(X_train[batch_ids], dtype\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    239\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor(y_train[batch_ids], dtype\u001b[38;5;241m=\u001b[39my_train\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 241\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnmf_iterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mnmf_projection_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msample_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msave_kernel_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_kernel_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m x_batch, y_batch, batch_ids\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_kernel_matrix:\n",
      "File \u001b[1;32md:\\UIT\\nsNMF\\rfm-nmf\\rfm\\rfm\\nmfhtr.py:112\u001b[0m, in \u001b[0;36mKernelModel.nmf_iterate\u001b[1;34m(self, samples, x_batch, y_batch, nmf_fn, eta, sample_ids, batch_ids, save_kernel_matrix)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# update fixed coordinate block (for EigenPro)\u001b[39;00m\n\u001b[0;32m    111\u001b[0m kmat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_kernel_matrix(x_batch, batch_ids, samples, sample_ids)\n\u001b[1;32m--> 112\u001b[0m correction \u001b[38;5;241m=\u001b[39m \u001b[43mnmf_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkmat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Kiểm tra và điều chỉnh kích thước của correction\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m correction\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sample_ids):\n",
      "File \u001b[1;32md:\\UIT\\nsNMF\\rfm-nmf\\rfm\\rfm\\nmfhtr.py:211\u001b[0m, in \u001b[0;36mKernelModel.fit.<locals>.nmf_projection_fn\u001b[1;34m(grad, kmat)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrad\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, kmat shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkmat\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW_nmf shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mW_nmf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, H_nmf shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mH_nmf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, S_nmf shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mS_nmf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m W_nmf \u001b[38;5;241m@\u001b[39m S_nmf \u001b[38;5;241m@\u001b[39m(\u001b[43mH_nmf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x500 and 33x3)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from rfm.nmfhtr import KernelModel\n",
    "from rfm.kernels import laplacian\n",
    "\n",
    "# Thiết lập thiết bị\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Tạo dữ liệu ngẫu nhiên\n",
    "n_samples = 1000  # Số lượng mẫu\n",
    "n_features = 20   # Số lượng đặc trưng\n",
    "n_classes = 3     # Số lượng lớp (đầu ra)\n",
    "\n",
    "# Dữ liệu đầu vào (ngẫu nhiên)\n",
    "X_train = torch.randn(n_samples, n_features).to(DEVICE)\n",
    "X_val = torch.randn(n_samples // 10, n_features).to(DEVICE)\n",
    "\n",
    "# Nhãn đầu ra (ngẫu nhiên, one-hot encoding)\n",
    "y_train = torch.randint(0, n_classes, (n_samples,)).to(DEVICE)\n",
    "y_train = torch.nn.functional.one_hot(y_train, num_classes=n_classes).float()\n",
    "\n",
    "y_val = torch.randint(0, n_classes, (n_samples // 10,)).to(DEVICE)\n",
    "y_val = torch.nn.functional.one_hot(y_val, num_classes=n_classes).float()\n",
    "\n",
    "# Khởi tạo KernelModel với kernel Laplace\n",
    "bandwidth = 1.0  # Tham số bandwidth của kernel Laplace\n",
    "kernel_model = KernelModel(\n",
    "    kernel_fn=lambda x, y: laplacian(x, y, bandwidth=bandwidth),\n",
    "    centers=X_train,\n",
    "    y_dim=n_classes,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "print(\"Training KernelModel with Laplace kernel...\")\n",
    "# Huấn luyện mô hình\n",
    "print(\"Training KernelModel with Laplace kernel...\")\n",
    "results = kernel_model.fit(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    epochs=10,          # Số lượng epochs\n",
    "    mem_gb=4,           # Giới hạn bộ nhớ GPU\n",
    "    n_subsamples=500,   # Số lượng mẫu con để tính toán\n",
    "    bs=32,              # Batch size\n",
    "    eta=0.1,            # Learning rate\n",
    "    classification=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Dự đoán trên tập validation\n",
    "print(\"Predicting on validation data...\")\n",
    "predictions = kernel_model.forward(X_val)\n",
    "\n",
    "# Đánh giá độ chính xác\n",
    "accuracy = (predictions.argmax(dim=1) == y_val.argmax(dim=1)).float().mean().item()\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hoang\\anaconda3\\envs\\clean_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-25 15:46:54,494 - Training LaplaceRFM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders provided\n",
      "Time taken to prefit nmf with 70000 points: 0.62255859375 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Phần huấn luyện nên sửa thành\u001b[39;00m\n\u001b[0;32m     76\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining LaplaceRFM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m \u001b[43mlaplace_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43miters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Tham số này có thể conflict với epochs\u001b[39;49;00m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_points_to_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Nên để None để dùng toàn bộ data\u001b[39;49;00m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mM_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Tăng batch size để tận dụng GPU\u001b[39;49;00m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnmf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Nên tăng số epochs (10-50)\u001b[39;49;00m\n\u001b[0;32m     87\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\UIT\\nsNMF\\rfm-nmf\\rfm\\rfm\\recursive_feature_machine.py:238\u001b[0m, in \u001b[0;36mRecursiveFeatureMachine.fit\u001b[1;34m(self, train_data, test_data, iters, method, classification, verbose, M_batch_size, return_best_params, bs, return_Ms, lr_scale, total_points_to_sample, solver, fit_last_M, prefit_nmf, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iters):\n\u001b[0;32m    236\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m     test_mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore(X_test, y_test, bs, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    245\u001b[0m     log_data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_mse\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_mse}\n",
      "File \u001b[1;32md:\\UIT\\nsNMF\\rfm-nmf\\rfm\\rfm\\recursive_feature_machine.py:137\u001b[0m, in \u001b[0;36mRecursiveFeatureMachine.fit_predictor\u001b[1;34m(self, centers, targets, classification, bs, lr_scale, verbose, solver, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m         initial_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predictor_nmf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43minitial_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m                                               \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_predictor_lstsq(centers, targets, solver\u001b[38;5;241m=\u001b[39msolver)\n",
      "File \u001b[1;32md:\\UIT\\nsNMF\\rfm-nmf\\rfm\\rfm\\recursive_feature_machine.py:174\u001b[0m, in \u001b[0;36mRecursiveFeatureMachine.fit_predictor_nmf\u001b[1;34m(self, centers, targets, bs, lr_scale, verbose, initial_weights, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     ep_model\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m initial_weights\u001b[38;5;241m.\u001b[39mto(ep_model\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mep_model\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 174\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mep_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem_gb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmem_gb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ep_model\u001b[38;5;241m.\u001b[39mweight\n",
      "File \u001b[1;32md:\\UIT\\nsNMF\\rfm-nmf\\rfm\\rfm\\nmfhtr.py:265\u001b[0m, in \u001b[0;36mKernelModel.fit\u001b[1;34m(self, X_train, y_train, X_val, y_val, epochs, mem_gb, n_subsamples, bs, eta, n_eval, run_epoch_eval, lr_scale, verbose, seed, classification, threshold, early_stopping_window_size, eval_interval)\u001b[0m\n\u001b[0;32m    262\u001b[0m     x_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor(X_train[batch_ids], dtype\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    263\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor(y_train[batch_ids], dtype\u001b[38;5;241m=\u001b[39my_train\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnmf_iterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mnmf_projection_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msample_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msave_kernel_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_kernel_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m x_batch, y_batch, batch_ids\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_kernel_matrix:\n",
      "File \u001b[1;32md:\\UIT\\nsNMF\\rfm-nmf\\rfm\\rfm\\nmfhtr.py:119\u001b[0m, in \u001b[0;36mKernelModel.nmf_iterate\u001b[1;34m(self, samples, x_batch, y_batch, nmf_fn, eta, sample_ids, batch_ids, save_kernel_matrix)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# update fixed coordinate block (for EigenPro)\u001b[39;00m\n\u001b[0;32m    118\u001b[0m kmat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_kernel_matrix(x_batch, batch_ids, samples, sample_ids)\n\u001b[1;32m--> 119\u001b[0m correction \u001b[38;5;241m=\u001b[39m \u001b[43mnmf_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkmat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Kiểm tra và điều chỉnh kích thước của correction\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m correction\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sample_ids):\n",
      "File \u001b[1;32md:\\UIT\\nsNMF\\rfm-nmf\\rfm\\rfm\\nmfhtr.py:222\u001b[0m, in \u001b[0;36mKernelModel.fit.<locals>.nmf_projection_fn\u001b[1;34m(grad, kmat)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnmf_projection_fn\u001b[39m(grad, kmat):\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# Gọi reconstruct_X và đảm bảo X_hat là tensor PyTorch\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     X_hat \u001b[38;5;241m=\u001b[39m \u001b[43mreconstruct_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW_tensor_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS_tensor_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH_tensor_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# Chuyển X_hat từ numpy array thành PyTorch tensor\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     X_hat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_hat, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# Di chuyển tensor về đúng device\u001b[39;00m\n",
      "File \u001b[1;32md:\\UIT\\nsNMF\\rfm-nmf\\rfm\\rfm\\nmf.py:136\u001b[0m, in \u001b[0;36mreconstruct_X\u001b[1;34m(W_list, S_list, H_final)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03mReconstruct the matrix X̂ = W₁ * S₁ * W₂ * S₂ * ... * Wₖ * Sₖ * Hₖ\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m- X_hat: Reconstructed matrix\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Ensure all matrices are at least 2D numpy arrays\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m W_list \u001b[38;5;241m=\u001b[39m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m W \u001b[38;5;129;01min\u001b[39;00m W_list]\n\u001b[0;32m    137\u001b[0m S_list \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39matleast_2d(S) \u001b[38;5;28;01mfor\u001b[39;00m S \u001b[38;5;129;01min\u001b[39;00m S_list]\n\u001b[0;32m    138\u001b[0m H_final \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_2d(H_final)\n",
      "File \u001b[1;32mc:\\Users\\hoang\\anaconda3\\envs\\clean_env\\Lib\\site-packages\\numpy\\core\\shape_base.py:121\u001b[0m, in \u001b[0;36matleast_2d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m    119\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[1;32m--> 121\u001b[0m     ary \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ary\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    123\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hoang\\anaconda3\\envs\\clean_env\\Lib\\site-packages\\torch\\_tensor.py:1149\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from rfm import LaplaceRFM, GeneralizedLaplaceRFM, GaussRFM, NTKModel\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "import wandb\n",
    "\n",
    "# Cấu hình logging: ghi log vào file và in ra console\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "\n",
    "# File handler: ghi log vào output.txt\n",
    "file_handler = logging.FileHandler(\"output.txt\")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Console handler: in log ra console\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setFormatter(formatter)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# Hàm chuyển đổi batch: chuyển đổi nhãn thành one-hot encoding với 10 lớp\n",
    "def one_hot_collate(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    images = torch.stack(images, 0)\n",
    "    labels = torch.tensor(labels)\n",
    "    # Chuyển đổi nhãn sang one-hot (float)\n",
    "    labels = F.one_hot(labels, num_classes=10).float()\n",
    "    \n",
    "    # Đảm bảo rằng cả images và labels đều ở trên cùng một thiết bị\n",
    "    if torch.cuda.is_available():\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# Thiết lập thiết bị và bộ nhớ GPU (nếu có)\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    DEV_MEM_GB = torch.cuda.get_device_properties(DEVICE).total_memory // 1024**3 - 1\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    DEV_MEM_GB = 8\n",
    "\n",
    "# Định nghĩa transform: chuyển đổi ảnh MNIST thành tensor và làm phẳng thành vector 784 chiều\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))\n",
    "])\n",
    "\n",
    "# Tải dataset MNIST cho training và testing\n",
    "full_train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Chia tập train ra thành một phần nhỏ để tránh làm đầy bộ nhớ\n",
    "subset_size = 10000  # Có thể điều chỉnh theo khả năng của máy\n",
    "train_subset, _ = random_split(full_train_dataset, [subset_size, len(full_train_dataset) - subset_size])\n",
    "\n",
    "# Tạo DataLoader cho tập train và test, sử dụng collate_fn để chuyển đổi nhãn\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, collate_fn=one_hot_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=one_hot_collate)\n",
    "\n",
    "# Tham số cần điều chỉnh\n",
    "laplace_model = LaplaceRFM(\n",
    "    bandwidth=1.,  # Nên tune parameter này (thử giá trị 0.5-5)\n",
    "    device=DEVICE,\n",
    "    mem_gb=DEV_MEM_GB,\n",
    "    diag=False\n",
    ")\n",
    "\n",
    "# Phần huấn luyện nên sửa thành\n",
    "\n",
    "logger.info(\"Training LaplaceRFM\")\n",
    "laplace_model.fit(\n",
    "    train_data=train_loader,\n",
    "    test_data=test_loader,\n",
    "    iters=3,  # Tham số này có thể conflict với epochs\n",
    "    classification=True,\n",
    "    total_points_to_sample=subset_size, # Nên để None để dùng toàn bộ data\n",
    "    M_batch_size=64,  # Tăng batch size để tận dụng GPU\n",
    "    method='nmf',\n",
    "    verbose=True,\n",
    "    epochs=3,  # Nên tăng số epochs (10-50)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
